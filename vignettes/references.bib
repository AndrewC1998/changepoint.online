@Article{GamRod,
author="Gama, Jo{\~a}o
and Rodrigues, Pedro Pereira",
editor="Kok, Joost N.
and Koronacki, Jacek
and Lopez de Mantaras, Ramon
and Matwin, Stan
and Mladeni{\v{c}}, Dunja
and Skowron, Andrzej",
title="Stream-Based Electricity Load Forecast",
booktitle="Knowledge Discovery in Databases: PKDD 2007",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="446--453",
abstract="Sensors distributed all around electrical-power distribution networks produce streams of data at high-speed. From a data mining perspective, this sensor network problem is characterized by a large number of variables (sensors), producing a continuous flow of data, in a dynamic non-stationary environment. Companies make decisions to buy or sell energy based on load profiles and forecast. We propose an architecture based on an online clustering algorithm where each cluster (group of sensors with high correlation) contains a neural-network based predictive model. The goal is to maintain in real-time a clustering model and a predictive model able to incorporate new information at the speed data arrives, detecting changes and adapting the decision models to the most recent information. We present results illustrating the advantages of the proposed architecture, on several temporal horizons, and its competitiveness with another predictive strategy.",
isbn="978-3-540-74976-9"
}

@article{KoopPotter,
 ISSN = {00346527, 1467937X},
 URL = {http://www.jstor.org/stable/4626160},
 abstract = {This paper develops a new approach to change-point modelling that allows the number of change-points in the observed sample to be unknown. The model we develop assumes that regime durations have a Poisson distribution. It approximately nests the two most common approaches: the time-varying parameter (TVP) model with a change-point every period and the change-point model with a small number of regimes. We focus considerable attention on the construction of reasonable hierarchical priors both for regime durations and for the parameters that characterize each regime. A Markov chain Monte Carlo posterior sampler is constructed to estimate a version of our model, which allows for change in conditional means and variances. We show how real-time forecasting can be done in an efficient manner using sequential importance sampling. Our techniques are found to work well in an empirical exercise involving U.S. GDP growth and inflation. Empirical results suggest that the number of change-points is larger than previously estimated in these series and the implied model is similar to a TVP (with stochastic volatility) model.},
 author = {Gary Koop and Simon M. Potter},
 journal = {The Review of Economic Studies},
 number = {3},
 pages = {763--789},
 publisher = {[Oxford University Press, Review of Economic Studies, Ltd.]},
 title = {Estimation and Forecasting in Models with Multiple Breaks},
 volume = {74},
 year = {2007}
}

@article{Golabozsu,
 author = {Golab, Lukasz and \"{O}zsu, M. Tamer},
 title = {Issues in Data Stream Management},
 journal = {SIGMOD Rec.},
 issue_date = {June 2003},
 volume = {32},
 number = {2},
 month = jun,
 year = {2003},
 issn = {0163-5808},
 pages = {5--14},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/776985.776986},
 doi = {10.1145/776985.776986},
 acmid = {776986},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@article{KillickPELT,
issn = {0162-1459},
abstract = {In this article, we consider the problem of detecting multiple changepoints in large datasets. Our focus is on applications where the number of changepoints will increase as we collect more data: for example, in genetics as we analyze larger regions of the genome, or in finance as we observe time series over longer periods. We consider the common approach of detecting changepoints through minimizing a cost function over possible numbers and locations of changepoints. This includes several established procedures for detecting changing points, such as penalized likelihood and minimum description length. We introduce a new method for finding the minimum of such cost functions and hence the optimal number and location of changepoints that has a computational cost, which, under mild conditions, is linear in the number of observations. This compares favorably with existing methods for the same problem whose computational cost can be quadratic or even cubic. In simulation studies, we show that our new method can be orders of magnitude faster than these alternative exact methods. We also compare with the binary segmentation algorithm for identifying changepoints, showing that the exactness of our approach can lead to substantial improvements in the accuracy of the inferred segmentation of the data. This article has supplementary materials available online.},
journal = {Journal of the American Statistical Association},
pages = {1590--1598},
volume = {107},
publisher = {Taylor & Francis Group},
number = {500},
year = {2012},
title = {Optimal Detection of Changepoints With a Linear Computational Cost},
language = {eng},
author = {Killick, R. and Fearnhead, P. and Eckley, I. A.},
keywords = {Dynamic Programming ; Pelt ; Segmentation ; Structural Change},
}

@article{Mattesonecp,
abstract = {The concept of homogeneity plays a critical role in statistics, both in its applications as well as its theory. Change point analysis is a statistical tool that aims to attain homogeneity within time series data. This is accomplished through partitioning the time series into a number of contiguous homogeneous segments. The applications of such techniques range from identifying chromosome alterations to solar flare detection. In this manuscript we present a general purpose search algorithm called cp3o that can be used to identify change points in multivariate time series. This new search procedure can be applied with a large class of goodness of fit measures. Additionally, a reduction in the computational time needed to identify change points is accomplish by means of probabilistic pruning. With mild assumptions about the goodness of fit measure this new search algorithm is shown to generate consistent estimates for both the number of change points and their locations, even when the number of change points increases with the time series length. A change point algorithm that incorporates the cp3o search algorithm and E-Statistics, e-cp3o, is also presented. The only distributional assumption that the e-cp3o procedure makes is that the absolute $\alpha$th moment exists, for some $\alpha\in(0,2)$. Due to this mild restriction, the e-cp3o procedure can be applied to a majority of change point problems. Furthermore, even with such a mild restriction, the e-cp3o procedure has the ability to detect any type of distributional change within a time series. Simulation studies are used to compare the e-cp3o procedure to other parametric and nonparametric change point procedures, we highlight applications of e-cp3o to climate and financial datasets.},
year = {2015},
title = {Change Points via Probabilistically Pruned Objectives},
author = {James, Nicholas A. and Matteson, David S.},
keywords = {Statistics - Methodology},
}

@article{Lai,
 ISSN = {00359246},
 URL = {http://www.jstor.org/stable/2345934},
 abstract = {After a brief survey of a large variety of sequential detection procedures that are widely scattered in statistical references on quality control and engineering references on fault detection and signal processing, we study some open problems concerning these procedures and introduce a unified theory of sequential changepoint detection. This theory leads to a class of sequential detection rules which are not too demanding in computational and memory requirements for on-line implementation and yet are nearly optimal under several performance criteria.},
 author = {Tze Leung Lai},
 journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
 number = {4},
 pages = {613--658},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {Sequential Changepoint Detection in Quality Control and Dynamical Systems},
 volume = {57},
 year = {1995}
}

 @Article{changepointvignette,
    title = {{changepoint}: An {R} Package for Changepoint Analysis},
    author = {Rebecca Killick and Idris A. Eckley},
    journal = {Journal of Statistical Software},
    year = {2014},
    volume = {58},
    number = {3},
    pages = {1--19},
    url = {http://www.jstatsoft.org/v58/i03/},
  }
 
  @Manual{changepointrpackage,
    title = {{changepoint}: An {R} package for changepoint analysis},
    author = {Rebecca Killick and Kaylea Haynes and Idris A. Eckley},
    year = {2016},
    url = {https://CRAN.R-project.org/package=changepoint},
    note = {R package version 2.2.2},
  }
  
  @Article{ecprpackage,
    title = {{ecp}: An {R} Package for Nonparametric Multiple Change
      Point Analysis of Multivariate Data},
    author = {Nicholas A. James and David S. Matteson},
    journal = {Journal of Statistical Software},
    year = {2014},
    volume = {62},
    number = {7},
    pages = {1--25},
    url = {http://www.jstatsoft.org/v62/i07/},
  }
  
  @Article{cpmrpackage,
    title = {Parametric and Nonparametric Sequential Change Detection
      in {R}: The {cpm} Package},
    author = {Gordon J. Ross},
    journal = {Journal of Statistical Software},
    year = {2015},
    volume = {66},
    number = {3},
    pages = {1--20},
    url = {http://www.jstatsoft.org/v66/i03/},
  }
  
  @article{Lai2005,
issn = {1367-4803},
abstract = {Motivation: Array Comparative Genomic Hybridization (CGH) can reveal chromosomal aberrations in the genomic DNA. These amplifications and deletions at the DNA level are important in the pathogenesis of cancer and other diseases. While a large number of approaches have been proposed for analyzing the large array CGH datasets, the relative merits of these methods in practice are not clear. Results: We compare 11 different algorithms for analyzing array CGH data. These include both segment detection methods and smoothing methods, based on diverse techniques such as mixture models, Hidden Markov Models, maximum likelihood, regression, wavelets and genetic algorithms. We compute the Receiver Operating Characteristic (ROC) curves using simulated data to quantify sensitivity and specificity for various levels of signal-to-noise ratio and different sizes of abnormalities. We also characterize their performance on chromosomal regions of interest in a real dataset obtained from patients with Glioblastoma Multiforme. While comparisons of this type are difficult due to possibly sub-optimal choice of parameters in the methods, they nevertheless reveal general characteristics that are helpful to the biological investigator. Contact: peter_park@harvard.edu},
journal = {Bioinformatics},
pages = {3763--3770},
volume = {21},
publisher = {Oxford University Press},
number = {19},
year = {2005},
title = {Comparative analysis of algorithms for identifying amplifications and deletions in array CGH data},
author = {Lai, Weil R. and Johnson, Mark D. and Kucherlapati, Raju and Park, Peter J.},
keywords = {Algorithms–Methods ; Chromosome Mapping–Genetics ; Gene Amplification–Methods ; Gene Deletion–Methods ; Nucleic Acid Hybridization–Methods ; Oligonucleotide Array Sequence Analysis–Methods ; Reproducibility of Results–Methods ; Sensitivity & Specificity–Methods ; Software–Methods ; Software Validation–Methods;},
}

@article{Killick2010,
issn = {0029-8018},
abstract = {To link to full-text access for this article, visit this link: http://dx.doi.org/10.1016/j.oceaneng.2010.04.009 Byline: Rebecca Killick (a), Idris A. Eckley (a), Kevin Ewans (b), Philip Jonathan (c) Abstract: Changepoint analysis is used to detect changes in variability within GOMOS hindcast time-series for significant wave heights of storm peak events across the Gulf of Mexico for the period 1900-2005. To detect a change in variance, the two-step procedure consists of (1) validating model assumptions per geographic location, followed by (2) application of a penalized likelihood changepoint algorithm. Results suggest that the most important changes in time-series variance occur in 1916 and 1933 at small clusters of boundary locations at which, in general, the variance reduces. No post-war changepoints are detected. The changepoint procedure can be readily applied to other environmental time-series. Author Affiliation: (a) Department of Mathematics and Statistics, Lancaster University, Lancaster, LA1 4YF, UK (b) Shell International Exploration and Production, P.O. Box 60, 2280 AB Rijswijk, The Netherlands (c) Shell Technology Centre Thornton, P.O. Box 1, Chester, UK Article History: Received 19 September 2009; Accepted 29 April 2010},
journal = {Ocean Engineering},
volume = {37},
publisher = {Elsevier B.V.},
number = {13},
year = {2010},
title = {Detection of changes in variance of oceanographic time-series using changepoint analysis.(Report)},
language = {English},
author = {Killick, Rebecca and Eckley, Idris A. and Ewans, Kevin and Jonathan, Philip},
keywords = {Algorithms -- Analysis},
}

@article{Chen1997,
issn = {0162-1459},
abstract = {Abstract This article explores testing and locating multiple variance changepoints in a sequence of independent Gaussian random variables (assuming known and common mean). This type of problem is very common in applied economics and finance. A binary procedure combined with the Schwarz information criterion (SIC) is used to search all of the possible variance changepoints existing in the sequence. The simulated power of the proposed procedure is compared to that of the CUSUM procedure used by Inclán and Tiao to cope with variance changepoints. The SIC and unbiased SIC for this problem are derived. To obtain the percentage points of the SIC criterion, the asymptotic null distribution of a function of the SIC is obtained, and then the approximate percentage points of the SIC are tabulated. Finally, the results are applied to the weekly stock prices. The unknown but common mean case is also outlined at the end.},
journal = {Journal of the American Statistical Association},
pages = {739--747},
volume = {92},
publisher = {Taylor & Francis Group},
number = {438},
year = {1997},
title = {Testing and Locating Variance Changepoints with Application to Stock Prices},
author = {Chen, Jie and Gupta, A.K.},
keywords = {Asymptotic Distribution ; Consistency ; Cumulative Sum ; Hypothesis Testing ; Information Criterion ; Return Series ; Unbiased Estimator},
}

 @Article{gstat,
    title = {Multivariable geostatistics in {S}: the gstat package},
    author = {Edzer J. Pebesma},
    journal = {Computers & Geosciences},
    year = {2004},
    volume = {30},
    pages = {683-691},
  }

@article{Haslett2006,
issn = {1436-3240},
abstract = {Since Haslett and Raftery’s paper Space-Time Modelling with Long-Memory Dependence: Assessing Ireland’s Wind Power Resource (1989) , modelling meteorological time series with long memory processes, in particular the ARFIMA model has become very common. Haslett and Raftery fitted an ARFIMA model on Irish daily wind speeds. In this paper, we try to reproduce Haslett and Raftery’s results (focusing on the dynamic of the wind process, and not on cross-correlation and space dependencies), and show that an ARFIMA model does not properly capture the behaviour of the series (in Modelling daily windspeed in Ireland section). Indeed, the series show a periodic behaviour, that is not taken into account by the ARFIMA model. Removing this periodic behaviour yields no results either, we therefore try to fit a GARMA model that takes into account both seasonality and long memory (in Seasonality and long memory using GARMA models section). If a GARMA process can be fitted to the data to model Irish daily data, we will show that these models could also be used to model Dutch hourly data.},
journal = {Stochastic Environmental Research and Risk Assessment},
pages = {141--151},
volume = {20},
publisher = {Springer-Verlag},
number = {3},
year = {2006},
title = {Wind in Ireland: long memory or seasonal effect?},
language = {eng},
address = {Berlin/Heidelberg},
author = {Bouette, Jean-Christophe and Chassagneux, Jean-François and Sibai, David and Terron, Rémi and Charpentier, Arthur},
keywords = {Ireland ; Memory ; Time ; Mathematical Models ; Wind;},
}

