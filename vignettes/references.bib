@Article{GamRod,
author="Gama, Jo{\~a}o
and Rodrigues, Pedro Pereira",
editor="Kok, Joost N.
and Koronacki, Jacek
and Lopez de Mantaras, Ramon
and Matwin, Stan
and Mladeni{\v{c}}, Dunja
and Skowron, Andrzej",
title="Stream-Based Electricity Load Forecast",
booktitle="Knowledge Discovery in Databases: PKDD 2007",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="446--453",
abstract="Sensors distributed all around electrical-power distribution networks produce streams of data at high-speed. From a data mining perspective, this sensor network problem is characterized by a large number of variables (sensors), producing a continuous flow of data, in a dynamic non-stationary environment. Companies make decisions to buy or sell energy based on load profiles and forecast. We propose an architecture based on an online clustering algorithm where each cluster (group of sensors with high correlation) contains a neural-network based predictive model. The goal is to maintain in real-time a clustering model and a predictive model able to incorporate new information at the speed data arrives, detecting changes and adapting the decision models to the most recent information. We present results illustrating the advantages of the proposed architecture, on several temporal horizons, and its competitiveness with another predictive strategy.",
isbn="978-3-540-74976-9"
}

@article{KoopPotter,
 ISSN = {00346527, 1467937X},
 URL = {http://www.jstor.org/stable/4626160},
 abstract = {This paper develops a new approach to change-point modelling that allows the number of change-points in the observed sample to be unknown. The model we develop assumes that regime durations have a Poisson distribution. It approximately nests the two most common approaches: the time-varying parameter (TVP) model with a change-point every period and the change-point model with a small number of regimes. We focus considerable attention on the construction of reasonable hierarchical priors both for regime durations and for the parameters that characterize each regime. A Markov chain Monte Carlo posterior sampler is constructed to estimate a version of our model, which allows for change in conditional means and variances. We show how real-time forecasting can be done in an efficient manner using sequential importance sampling. Our techniques are found to work well in an empirical exercise involving U.S. GDP growth and inflation. Empirical results suggest that the number of change-points is larger than previously estimated in these series and the implied model is similar to a TVP (with stochastic volatility) model.},
 author = {Gary Koop and Simon M. Potter},
 journal = {The Review of Economic Studies},
 number = {3},
 pages = {763--789},
 publisher = {[Oxford University Press, Review of Economic Studies, Ltd.]},
 title = {Estimation and Forecasting in Models with Multiple Breaks},
 volume = {74},
 year = {2007}
}

@article{Golabozsu,
 author = {Golab, Lukasz and \"{O}zsu, M. Tamer},
 title = {Issues in Data Stream Management},
 journal = {SIGMOD Rec.},
 issue_date = {June 2003},
 volume = {32},
 number = {2},
 month = jun,
 year = {2003},
 issn = {0163-5808},
 pages = {5--14},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/776985.776986},
 doi = {10.1145/776985.776986},
 acmid = {776986},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@article{KillickPELT,
issn = {0162-1459},
abstract = {In this article, we consider the problem of detecting multiple changepoints in large datasets. Our focus is on applications where the number of changepoints will increase as we collect more data: for example, in genetics as we analyze larger regions of the genome, or in finance as we observe time series over longer periods. We consider the common approach of detecting changepoints through minimizing a cost function over possible numbers and locations of changepoints. This includes several established procedures for detecting changing points, such as penalized likelihood and minimum description length. We introduce a new method for finding the minimum of such cost functions and hence the optimal number and location of changepoints that has a computational cost, which, under mild conditions, is linear in the number of observations. This compares favorably with existing methods for the same problem whose computational cost can be quadratic or even cubic. In simulation studies, we show that our new method can be orders of magnitude faster than these alternative exact methods. We also compare with the binary segmentation algorithm for identifying changepoints, showing that the exactness of our approach can lead to substantial improvements in the accuracy of the inferred segmentation of the data. This article has supplementary materials available online.},
journal = {Journal of the American Statistical Association},
pages = {1590--1598},
volume = {107},
publisher = {Taylor & Francis Group},
number = {500},
year = {2012},
title = {Optimal Detection of Changepoints With a Linear Computational Cost},
language = {eng},
author = {Killick, R. and Fearnhead, P. and Eckley, I. A.},
keywords = {Dynamic Programming ; Pelt ; Segmentation ; Structural Change},
}

@article{Mattesonecp,
abstract = {The concept of homogeneity plays a critical role in statistics, both in its applications as well as its theory. Change point analysis is a statistical tool that aims to attain homogeneity within time series data. This is accomplished through partitioning the time series into a number of contiguous homogeneous segments. The applications of such techniques range from identifying chromosome alterations to solar flare detection. In this manuscript we present a general purpose search algorithm called cp3o that can be used to identify change points in multivariate time series. This new search procedure can be applied with a large class of goodness of fit measures. Additionally, a reduction in the computational time needed to identify change points is accomplish by means of probabilistic pruning. With mild assumptions about the goodness of fit measure this new search algorithm is shown to generate consistent estimates for both the number of change points and their locations, even when the number of change points increases with the time series length. A change point algorithm that incorporates the cp3o search algorithm and E-Statistics, e-cp3o, is also presented. The only distributional assumption that the e-cp3o procedure makes is that the absolute $\alpha$th moment exists, for some $\alpha\in(0,2)$. Due to this mild restriction, the e-cp3o procedure can be applied to a majority of change point problems. Furthermore, even with such a mild restriction, the e-cp3o procedure has the ability to detect any type of distributional change within a time series. Simulation studies are used to compare the e-cp3o procedure to other parametric and nonparametric change point procedures, we highlight applications of e-cp3o to climate and financial datasets.},
year = {2015},
title = {Change Points via Probabilistically Pruned Objectives},
author = {James, Nicholas A. and Matteson, David S.},
keywords = {Statistics - Methodology},
}

@article{Lai,
 ISSN = {00359246},
 URL = {http://www.jstor.org/stable/2345934},
 abstract = {After a brief survey of a large variety of sequential detection procedures that are widely scattered in statistical references on quality control and engineering references on fault detection and signal processing, we study some open problems concerning these procedures and introduce a unified theory of sequential changepoint detection. This theory leads to a class of sequential detection rules which are not too demanding in computational and memory requirements for on-line implementation and yet are nearly optimal under several performance criteria.},
 author = {Tze Leung Lai},
 journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
 number = {4},
 pages = {613--658},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {Sequential Changepoint Detection in Quality Control and Dynamical Systems},
 volume = {57},
 year = {1995}
}

 @Article{changepointvignette,
    title = {{changepoint}: An {R} Package for Changepoint Analysis},
    author = {Rebecca Killick and Idris A. Eckley},
    journal = {Journal of Statistical Software},
    year = {2014},
    volume = {58},
    number = {3},
    pages = {1--19},
    url = {http://www.jstatsoft.org/v58/i03/},
  }
 
  @Manual{changepointrpackage,
    title = {{changepoint}: An {R} package for changepoint analysis},
    author = {Rebecca Killick and Kaylea Haynes and Idris A. Eckley},
    year = {2016},
    url = {https://CRAN.R-project.org/package=changepoint},
    note = {R package version 2.2.2},
  }
  
  @Article{ecprpackage,
    title = {{ecp}: An {R} Package for Nonparametric Multiple Change
      Point Analysis of Multivariate Data},
    author = {Nicholas A. James and David S. Matteson},
    journal = {Journal of Statistical Software},
    year = {2014},
    volume = {62},
    number = {7},
    pages = {1--25},
    url = {http://www.jstatsoft.org/v62/i07/},
  }
  
  @Article{cpmrpackage,
    title = {Parametric and Nonparametric Sequential Change Detection
      in {R}: The {cpm} Package},
    author = {Gordon J. Ross},
    journal = {Journal of Statistical Software},
    year = {2015},
    volume = {66},
    number = {3},
    pages = {1--20},
    url = {http://www.jstatsoft.org/v66/i03/},
  }
  
  @article{Lai2005,
issn = {1367-4803},
abstract = {Motivation: Array Comparative Genomic Hybridization (CGH) can reveal chromosomal aberrations in the genomic DNA. These amplifications and deletions at the DNA level are important in the pathogenesis of cancer and other diseases. While a large number of approaches have been proposed for analyzing the large array CGH datasets, the relative merits of these methods in practice are not clear. Results: We compare 11 different algorithms for analyzing array CGH data. These include both segment detection methods and smoothing methods, based on diverse techniques such as mixture models, Hidden Markov Models, maximum likelihood, regression, wavelets and genetic algorithms. We compute the Receiver Operating Characteristic (ROC) curves using simulated data to quantify sensitivity and specificity for various levels of signal-to-noise ratio and different sizes of abnormalities. We also characterize their performance on chromosomal regions of interest in a real dataset obtained from patients with Glioblastoma Multiforme. While comparisons of this type are difficult due to possibly sub-optimal choice of parameters in the methods, they nevertheless reveal general characteristics that are helpful to the biological investigator. Contact: peter_park@harvard.edu},
journal = {Bioinformatics},
pages = {3763--3770},
volume = {21},
publisher = {Oxford University Press},
number = {19},
year = {2005},
title = {Comparative analysis of algorithms for identifying amplifications and deletions in array CGH data},
author = {Lai, Weil R. and Johnson, Mark D. and Kucherlapati, Raju and Park, Peter J.},
keywords = {Algorithms–Methods ; Chromosome Mapping–Genetics ; Gene Amplification–Methods ; Gene Deletion–Methods ; Nucleic Acid Hybridization–Methods ; Oligonucleotide Array Sequence Analysis–Methods ; Reproducibility of Results–Methods ; Sensitivity & Specificity–Methods ; Software–Methods ; Software Validation–Methods;},
}

